由夏嘉怡完成：
# 8

### 在不确定状态识别的多个记录系统中估计种群大小

Davide Di Cecco

*Istat**，意大利罗马国家统计研究所*



内容

8.1介绍*..*........................................................169

8.2之前的潜在的类模型*..*.....................172

8.2.1可分解的模型*..*................................... 174

8.2.2可识别性*..*............................................. 176

8.2.3 EM算法*..*............................................. 176

8.2.4修正参数*..*........................................ 178

8.2.5不同组件的混合物*..*..................... 178

8.2.6模型选择*..*........................................... 179

8.3观测到的捕获概率的异质性*..*...............181

​          8.3.1协变量的使用…………………………………………182

​	      8.3.2不完整的列表.............................................186

8.4 评估潜在类A贝叶斯方法的解释………………………186

8.5

​          8.5.1 密度算法…………………………189

​          8.5.2 模拟结果…………………………191



### 8.1 介绍

​	我们考虑通过整合多个数据源来估计感兴趣的总体(或“目标群体”)的大小的问题。每个数据源都提供了我们总体的单位列表。在此背景下，我们确定了三种可能的场景:

1.我们目标人群的每个单位都包含在至少一个来源中，但单位的识别并非没有错误:一些范围外的单位被错误地列入名单，反之亦然，我们人口中的一些单位被错误地确定为范围外;

 2.所有观察到的单位都被正确地识别为属于或不属于目标人群。然而，有些单位没有在任何可用的来源中被征募。所以，我们的名单存在覆盖不足的问题;

 3.不是所有的单位都包含在手边的数据和观察到的单位中不能根据目标人群正确分类。

​	第一种情况基本上可以被定性为错误分类的情况。我们可以利用我们所掌握的信息冗余，通过对冗余的随机性做一些假设来估计错误分类错误，因此，我们甚至可以估计出属于目标人群的单位级概率。

​	第二个场景代表捕获-再捕获设置的典型情况，其中我们有一组不完整的列表(它们不覆盖所有单元，并且一些未观察到的单元没有在任何列表中注册)和重叠的列表(一个单元可以在多个源中注册)。被捕获的事件对应于在列表中被注册的事件。与前面的场景不同，我们可以只估计未被观察到的单元的数量。

​	在第三种场景中，也就是本章的重点，我们假设检测的不确定性和状 态识别的不确定性这两个问题都存在于手头的数据中。我们本质上是指一个捕获-再捕获设置，在这个设置中，单位识别中没有错误的经典假设是放松的。在这种情况下，错误分类错误可以被重新表述为“错误捕获”。

​	请注意，在我们正在考虑的捕获-再捕获设置中，捕获不受研究人员控制。事实上，捕获场合由通常为不同目的而设置的报告系统的集合组成。从广 义上讲，被一个来源报道的事实，反映的是一个具有行政性质的事件。

​	被错误捕获的原因可能有几种。一般来说，各种来源的范围可能会有很大的不同，可能会与我们的目标人群有所不同。所以，每个列表都可能包 含不同的范围外单元的亚群。范围上的差异可能是由于单位定义上不容易 被检测到的差异。例如，与已登记事件有关的可用信息、它们的时间描述、它们的法律定义可能在每个来源中都有所不同，这些方面的协调可能不会 没有错误，因此，将单位分配给我们的目标人群可能也不会没有错误。在 每个列表中，可能会由于注册/取消的延迟而出现错误。合并数据源时，识别单元时的错误可能导致重复或错误链接。

​	显然，任何一条可用的信息都应该包括在我们列表中的错误案例的识别过程中，并且，理想情况下，识别和删除虚假案例应该是我们的第一个阶段分析，之后可以对“干净的”数据使用一些捕获-再捕获技术。

​	然而，在许多情况下，现有的信息不足以挑出每一个错误的捕获，并且会有一定部分的不确定性，我们没有能力识别错误的原因。

​	对于这些情况，我们的方法包括将所有可能的(残余)错误定义为随机分类错误，并且我们提出了一种基于使用潜在类模型来估计它们的无监督方法。在这种情况下对分类错误的引用是很容易接受的，只要目标总体的归属是由辅助变量的值定义的。例如，如果将单位定义为一定年龄范围内的人，那么变量“年龄”的不确定性将完全体现在单位的分类中。然而，即使在这样的分类机制本身并不明显的情况下，这种对问题的看法也是有用的。

​	利用潜在变量来模拟一个单元的“真实”潜在状态，是行为科学和社 会科学的常见做法。在这些领域，潜变量通常代表一个不能直接观察到的 概念，只能通过相关指标来衡量。[4]中深入描述的另一个不同的概念是， 当观察到的(显化的)变量是所需变量的实际测量值，而代表其真实值的潜 变量是定义良好且可测量的，具有已知数量的模态。在这种情况下，我们 认为每个测量都可能受到误差的影响，信息的冗余使我们能够估计潜在变 量，并以无监督的方式评估每个测量源的准确性。这一概念应用的一个明 显例子是在多重诊断测试的潜在类模型中(概述见[38])，其中每个测试都有 假阳性和假阴性率，潜在变量识别真实的医疗状态。在我们的模型中，我 们引用后一种概念，其中二进制潜变量标识范围内和范围外的单位，而显 变量，即观察到的捕获，可以是假的也可以是真的，并且可以被解释为对 该潜变量的潜在错误测量。请注意，观察到的和潜在变量都是二进制的。 有一些捕获-再捕获模型的例子，对观察到的和潜在变量具有不同数量的模 态，即在多状态模型中(参见，例如，[27])，以解释状态分配中的不确定性。然而，我们将局限于二元情况。

​	在第8.2节中，我们用形式化的术语描述了模型，并给出了关于估计、可识别性和模型选择的几个细节。在第8.3节中，我们描述了使用协变量来模拟捕获概率的异质性，以及不可捕获的子种群的特定情况。在第8.4 节中，我们提供了一些关于使用我们在模型中提出的潜在类的可维持性的观察结果。在第8.5节中，我们提出了模型的贝叶斯方法。



### 8.2捕获-再捕获的潜在类模型

​	形式上，设*k*为列表的个数(或捕获场合)。设$Yi$为随机变量，表示一个单元是否被第i个源捕获(即被列在第i个*列表*上):


$$
Yi=\begin{cases} 1，如果单位在第i个列表中被捕获\\0， 其他\end{cases}
$$

​	我们有一个*k*个变量的数组$Yi=(Y1,...,Yk)$表示一个单元在*k*个不同列表中的捕获。每个单元观测到的二进制数组(在捕获-再捕获文献中通常称为捕获历史)记为$y= (y1，…,yk)$。

​	设$U$为任意列表所能捕获的所有单位的集合，即*$k$个*源的目标总体的并集。设$U1$为我们的目标总体。它必须是$U1\subset U$，以便不存在任何无法捕捉的单位。我们可以用某些来源无法捕捉的单位来处理这种情况，但不是所有的(参见第 8.3.2节)。$U$的基数*，$|U|$记为$N$，而$|U1|=N1$。

​	观测到的单元可以在$2k$列联表[n~y~]~y∈{0,1}^k~中进行分类，其中n~y~表示具有捕获历史$y$的单元数。观测到的单元总数为${\textstyle \sum_{y\ne0 }^{}}$n~y~ = n~obs~，而$N$=$n$~obs~+$n$~0~.

​	识别属于我们目标人群的单位的潜变量记为
$$
X=\begin{cases} 1，如果一个单位属于U1\\0， 其他\end{cases}
$$
 

​	而$n$~x,y~表示存在捕获历史$\underline{y}$的潜在类$x$的单元数，因此${\textstyle \sum_{x\in 0,1}^{}} n_{x,y}=n_y$,而$n_{0,\underline{0}}$是$U$中但未捕获的单元数。

​	对于模型分布我们将使用[14]中引入的表示法，其中$P(\underline{Y}=\underline{y})=\pi_y$。当随机变量从上下文看不清楚时，上标将最终表示是随机变量，因此，例如$\pi^{X,Y_k}_{10}$表示概率$P(X=1,Y_k)$.我们考虑的模型类别可以表示为以下的混合模型：
$$
\pi_{\underline{y}}=\sum_{x\in 0,1}^{} \pi_x\pi_{\underline{y}|x}
$$
​	其中$\pi_{\underline{y}|x}$是条件概率$P(\underline{Y}=Y|x=x)$，$\pi_x$是属于潜在类$x$的边际概率，即一个随机单位属于或不属于目标群体的概率，构成状态识别的不确定性估计混合模型的权重参数。因此，似然函数为：
$$
L(\pi_{\underline{y}};n_{\underline{y}})\propto \prod_{y}^{} \pi_{\underline{y}}^{n_\underline{y}}=\prod_{y}^{}(\sum_{x}^{} \pi_x\pi_{\underline{y}|x})^{n_{\underline{y}}} 
$$
​	我们在这门课上可以考虑的最简单的模型如下：
$$
\pi_{\underline{y}}=\sum_{x\in0,1 }^{}\prod_{i=1}^{k}\pi_{y_i|x} 
$$
​	满足局部独立假设，即显示变量在$X$上是有条件独立的。这类模型在捕获-再捕获中对捕获概率中未观察到的异质性建模的应用是已知的(参见，例如[1])。然而请注意，局部独立假设在我们的设置中几乎是站不住脚的。正如我们已经说过的，我们正在考虑一个不受研究人员控制的捕获设置。因此，即使我们以潜在变量的值为条件，在不同列表中相同单元的捕获之间也可能存在正依赖性和负依赖性，因为在一个列表中记录的单元可能比未记录在该列表中的单元更有可能(或更少)出现在第二个列表中。

​	人们提出了各种方法来建模潜在类模型中的依赖关系，例如随机效应([28]，[8])，或多个潜在变量([10])。在贝叶斯上下文中，[23]以非参数的方式提出了一个先于模型依赖的狄利克雷过程。然而，可以追溯到[11]在捕获-再捕获中的经典方法是通过对数线性模型直接对这些依赖项建模;因此，为了探索显变量和潜在变量之间更复杂的依赖结构，我们将考虑一类具有潜在变量*X*的分层对数线性模型，该模型与所有显变量相互作用。

​	已经证明(参见，例如，[15])模型(8.2)等效于对数线性模型：
$$
[XY_1]...[XY_k],
$$
​	其中我们使用经典的分层对数线性模型的符号，只报告高阶交互项(有时称为生成器)。模型(8.3)是我们将考虑的最简单的情况:相对于(8.3)的每一个额外的交互参数都代表了对局部独立假设的偏差。术语局部依赖模型(Local Dependence model)有时用于这种设置。关于这个模型用于捕获-再捕获的应用，请参见例如[5]和[31]。

​	我们的目标是估计目标种群$N_1,i.e.$，即我们想估计$X=1$的单位（包括捕获和未捕获）的数量。我们有$N_1={\textstyle \sum_{y\ne 0}^{}n_{1,y}+n_{1,\underline{0}}} $,也就是说，$N1$等于每个捕获历史的范围内单元的数量之和，包括没有在任何列表中捕获的单元。



### 8.2.1可分解模型

​	在这里，我们介绍了模型的子类，称为可分解模型，这些模型将在以下内容中使用。在下一类中，我们首先介绍了依赖关系图。依赖关系图Gofajointcategoricaldis三分布是节点呈现变量的无向简单图，并且任何两个节点都是相邻的，除非相对变量是独立的（条件下是不稳定的）。我们可以将其图形化为依赖图形Gexhaustively定义了其联合分布的结构，即，如果联合分布不受G定义的拓扑的约束。注意，在图形化线性模型中，这相当于说，该模型完全包括了G集团提出的所有相互作用项，即G的延迟循环的产生者。阿莫德里被认为是可分解的，可以分解为依赖关系图。吉舒尔达尔，即，如果任何一个古罗马诺循环有一个单词（一个不是连接两个顶点的循环的一部分的数据）。如果阿莫德里是可分解，可以证明（[9]），联合分布因子是条件分布的乘积。

​	其中，设$(C_1...C_g)$为关联图G的最大团，$( {\textstyle \bigcup_{i=1}^{g}}C_i =G)$，则存在一个序${C_{\delta(1)},...,C_{\delta(g)}}$状态识别的不确定性估计，如果我们定义分隔符集$S_2,...S_g$为：
$$
S_i=C_{\delta(i)}\cap \bigcup_{j=1}^{i-1}  C_{\delta(j)}\qquad i=2,...,g
$$
我们有这个

（1）每个分隔符$S_i$为$G$的团；

（2）每个$S_i$包含在其中一个最大的团$C_{\delta(j)}$，$\delta(j)<i$；

（3）联合分布可以写成如下形式：
$$
\prod_{i=1}^{g}\pi^{C_i}(\prod_{j=2}^{g} \pi^{S_i}) ^{-1}
$$
其中$\pi$除以一个（子）图是作为（子）图中包含的变量的（边际）分布。

​	然后，如果我们将条件概率$\pi^{X}$表示为$\pi^{C_1|X}$（稍微滥用了符号），我们可将可分解分布写成下面的乘积：
$$
\pi^{C_1}\prod_{i=2}^{g}\pi^{C_i|S_i}. 
$$
​	举例来说，请参考图8.1中$Y=(A,B,C,D)$四个来源的图表。

​	我们只有两个具有该依赖关系图的分层对数线性模型：
$$
[AX][BX][CX][DX][CD]\qquad and\qquad [AX][BX][CDX].
$$
只有第二种是图形化的，因为图形是和弦的，所以它是可分解的。实际上，我们有$C_1=${$A,X$},$C_2$={$B,X$}，$C_3$={$C,D,X$},$S_2$={X},$S_3$={$X$},模型可以写成：
$$
\pi_{\underline{y}}=\sum_{x}^{}\pi_x\pi_{a|x}\pi_{b|x}\pi_{cd|x} 
$$
可分解模型具有一些计算优势，正如我们将在本章的其余部分中看到的那样。

以下内容为万亚珂完成：
# 8.3 观察到的捕获概率的异质性

## 8.3.1 协变量的使用

即使我们对列表之间的所有现有依赖关系进行建模，也可能存在仍会有一些无法解释的变化，这是因为个人被捕获的倾向性。一些捕获概率的异质性可以由一组协变量来解释，这些协变量必须包括在模型中。

如果未能对个体捕获概率中的列表依赖性或异质性进行建模，通常会导致对种群大小的有偏估计。然而请注意，这两个方面是不容易分开的。一个具有足够数量参数y的对数线性模型可以代表$$ \left\{ 0,1 \right\} ^{k}$$上的任何分布；因此，原则上总是有可能找到具有任何拟合优度水平的（可能是过度参数化的）模型。如果在模型中不包含个体异质性的相关来源，就会导致列表之间的虚假依赖关系，并且可能会错误地包含在模型中的虚假参数。

单个协变量的使用通常包括在模型中的两种方式之一（关于对数线性模型中两种方法的分析，见[37])。第一种方法是使用观察到的协变量来影响模型参数。也就是说，我们重新参数化潜伏类成员的概率（混合权重$$\pi _ { x }$$)和/或条件捕获概率$$ \pi _{y|x}$$，以一组协变量为基础。在这种方法中，协变量明确地具有解释变量的作用；它们既可以是分类的，也可以是连续的，而且有可能限制它们对特定参数的影响。通过将对数线性模型的公式转化为多项logit模型，可以通过几种方式实现参数化模型（见[39]、[43]、[35]、[36]）。

第二种方法，只有在所有协变量都是分类的时才可用，将它们作为清单变量。也就是说，我们为联合分布$$ \pi _{y,v}$$定义了一个模型，其中V是我们的协变量集。通过这种方式，我们可以对所有清单变量（捕获或协变量）之间的关系进行建模，并通过几种方式调整它们的依赖图。

必须指出的是在这种方法中，协变量并不一定存在影响$$N{1}$$的估计，除非它与其他证明的依赖关系变量是经过精心选择的。估计的不变性与对数线性模型的坍陷性有关。假设我们在一组变量Y上有一个对数线性模型M，我们考虑变量Y‘的一个子集，以及相对诱导对数线性模型M’，它只保持M相对于Y’中的所有变量的参数。如果模型M‘对每个单元格$$n{y^{\prime}}$$的估计等于模型M所对应的边际估计，则称M在Y’以上是可折叠的。设G为M的依赖图，H为Y/Y ’上的诱导子图，即未包含在Y‘中的G的变量图。Asmussen和Edwards [3]找到了可折叠的充分必要条件，即如果H的每个连通分量的G边界在M在Y‘上是可折叠的，构成M’的生成器。那么，如果$$ \pi _{x,y,v}$$的对数线性模型可在（X，Y）上折叠，那么协变量不会改变$$N{1}$$的估计。关于这方面，也可以看本书的第七章。

举个例子，假设我们想在图8.1的模型中包含协变量V。然后,建立模型

$$ \left[ AX \right] \left[ BX \right] \left[ CDX \right] \left[ CDV\right]$$

在{A、B、C、D、X}上是可折叠的，因为C和D在图中是连通的，而V不会改变$$N{1}$$的最终估计。相反，模型

$$ \left[ AX \right] \left[ BX \right] \left[ CDX \right] \left[ AV \right] \left[ CV\right]$$

是不可折叠的，因为A和C不连接，而V会影响$$N{1}$$的估计。

然而，请注意，这只对观察到的变量有效：如果V与潜在的X相互作用，那么它通常不会是可折叠的。例如，模型

$$ \left[ AVX \right] \left[ BX \right] \left[ CDX \right] ,$$

其中列表A的过覆盖误差随V变化，即使{A,X}是图的一个派系，在{A、B、C、D、X}上不可折叠。

值得注意的是，如果我们对估计由协变量确定的每个地层的种群大小感兴趣，那么即使是一个可折叠的模型也可能是有用的，因为我们可以简单地估计所有值v的数量$$n \frac{Y_{}}{0}\frac{V}{v}$$。

## 8.3.2 不完整的列表

捕获概率的异质性的一个极端情况是由不可捕获的亚种群来表示的，即被捕获的概率为零的单位。在这里，我们处理已确定的亚种群的情况，即已知的一个或多个列表（但不是全部）无法接受的单位。这个问题在实践中经常发生，因为当一个源针对我们感兴趣的人群的一个子集时，它就会发生。我们不想丢失那些我们将称之为“不完整来源”中可用的信息；然而，我们需要考虑它们在模型中的不完整性。也就是说，如果我们忽略列表的结构不完全性，并将不可捕获的单位视为抽样零，那么对种群规模的结果估计可能会有严重的偏差。

我们假设我们对每个不完整的列表都无法捕获的亚种群（或地层）有一个完美的知识。因此，U被划分为不同的不完整列表不运行的层。这可以通过分层变量S形式化划分U。由于S是已知的，我们可以采用一种简单的方法，用不同的模型分别估计每个地层的亚种群的大小。每个模型将只包括相对地层上的列表，然后将估计数相加将得出总人口规模估计数。然而，这种方法将极大地限制我们可以考虑的可识别模型的范围，因为我们经常遇到以下情况：不完整的列表有单独的目标，只有一个小子集，所有列表操作。例如，考虑4个列表和2个层的简单情况，一个是所有列表操作，另一个是只有3个列表操作。在第二层中，我们可以只考虑几个简单的对数线性模型，而一个潜在的类模型是不可识别的。

另一种方法是将未被不完整列表所覆盖的单元的不可观察捕获视为缺失信息。然后，将这些地层中的单元视为部分分类，即好像捕获历史部分缺失，然后我们估计缺失的部分。当然，潜在的假设是，在其他列表的条件下，每个不完整列表在地层中的分布是相同的，也就是说，我们假设一个随机缺失（MAR）机制(见[19]，章.3.2见[39])。如果这个假设是站得住脚的，我们可以在一个模型中包含所有记录，即使存在不完整的列表。另一方面，当假设不正确时，所得到的估计可能会有偏差。

使用对数线性模型来推断列联表中的部分缺失信息是众所周知的（见[30]）。这种方法在捕获中的应用，在[44]中也进行了探索。扩展到存在潜在变量的情况并没有任何困难，因为它不需要对第8.2.3节中描述的算法进行很少的修改。但是，请注意，这两个方面（潜在变量X和不完整的列表）不能很容易地用对数线性模型单独来解决。事实上，由于X与所有明显的变量相互作用，因此（X、Y、S）的对数线性模型将不能折叠到（Y、S）上。因此，如果有人想初步处理由于不完整的列表而造成的缺失，然后在完整的数据上估计潜在的类模型，他们应该定义和估计两个不同的对数线性模型。

假设分层变量S在一个有限的集合S = {s1，s2，...}中取值，以识别不同的不完整列表集合不工作的不同地层。对于每个地层s，我们观察到一组不同的边际计数$$T_{s}$$。我们假设存在一个完整的列联表$$T^{}= \left[ n{x,y,s}\right] ,$$，并且我们想要估计

$$N _ { 1 } = \sum _ { y \in\{ 0 , 1 \} ^ { k }{s\in S} } n _ { 1,y, s }$$

然后，在EM算法的E步中，对于每个层s，我们根据观察到的计数$$T _ { s } .$$有条件地计算$$T ^ { * }$$相应细胞的期望计数$$ \widehat{n}_{x,y,s}$$。

应注意$$T ^ { * }$$模型的依赖结构的选择。事实上，在许多情况下，S，或一些模式，可以构成一个有用的协变量来解释一些异质性捕获概率，我们想包括一些交互参数与其他变量，以这样一种方式模型不能折叠（X，Y）。然而，当且仅当处于某一地层的概率独立于所有不在该地层中运行的列表时，不完整列表的MAR假设才成立。因此，一个S与不完整的列表变量相互作用的模型将违反MAR假设，如果没有进一步的假设，它将无法被识别。相反，一个S不与任何其他变量相互作用的模型意味着缺失机制是完全随机的（MCAR）。

在存在不完整列表的情况下，我们有多个结构零单元格需要估计。它们的数量在每一层中的变化取决于不完整的列表的数量。形式上，设S=表示Y1，...，Ym，m < k不运行的地层。然后，对于该层，我们有以下$$2^{m+1}$$结构零细胞：

$$\{ n\begin{array}  { l  }  { X , Y _ { 1 } , \cdots , Y _ { m },  \cdots,Y _ { m } + 1 ,  Y _ { k  } , S } \\ { x,y _ { 1 }, \cdots,y_{m},0, \cdots,0,s } \end{array} _ { ( x , y_{1},\cdots,y_{m} \in \left\{ 0,1 \right\} ^{m+1}) }$$

在EM算法中排除，并在其收敛后进行估计。

例如，考虑列表A、B、C和D，其中列表A不完整，而S∈{s1，s2}表示A是否可操作。观察到的边际计数为$$T _ { 1 } = [ n _ { a b c d s _ { 1 } } ]$$和$$T _ { 1 } = [ n _ { b c d s_ { 2 } } ]$$。$$T ^ { * }$$的结构性零细胞为：

$$n{x0000s{1}}^{XABC}$$ , $$n_{x0000s_{2}}^{XABCDS}$$ ,and $$n_{x1000s_{2}}^{XABCDS}$$ , $$forx \in \left\{ 0,1\right\}$$

观测到的不完整数据的对数似然值为：

$$ \sum _{a,b,c,d}n_{abcds_{1}}\log \pi _{abcds_{1}}+ \sum _{b,c,d}n_{bcds_{2}}\log \pi _{bcds_{2}}$$

而EM算法的指定方式如下：

1. 随机初始化条件概率{$$ \widehat{\pi}_{x|abcds_{1}}$$}和{$$ \widehat{\pi}_{x|abcds_{2}}$$}；

2. 通过计算估计完整的列联表$$ \widehat{T}^{*}= \left[ n_{xabcds}\right]$$，排除结构零单元格（8.7）

$$\widehat{n}_{xabcds_{1}}=n_{abcds_{1}}\widehat{\pi}_{x|abcds_{1}}$$  $$ \forall cells s.t.(a,b,c,d)\neq(0,0,0,0)$$

$$\widehat{n}_{xabcds_{2}}=n_{abcds_{1}}\widehat{\pi}_{x|abcds_{2}}$$  $$ \forall cells s.t.(a,b,c,d)\neq(0,0,0,0)$$

3. 根据不可观测的结构零单元（8.7），计算当前$$ \widehat{T}^{*}$$上所选择的对数线性模型的MLE；

4. 更新条件概率的当前估计值

$$ \widehat{\pi}_{x|s_{1}abcd}$$=$$\frac{\widehat{n}_{xa_{n}abds_{1}}}{ \sum _{a,b,c,d}\widehat{n}_{xabcds_{1}}},$$，

$$ \widehat{\pi}_{x|s_{2}abcd}$$=$$\frac{\widehat{n}_{xa_{n}abds_{2}}}{ \sum _{a,b,c,d}\widehat{n}_{xabcds_{2}}},$$，



5.重复2-4次，直到收敛。

在收敛后，我们估计了单元格（8.7）。

请注意，在我们正在考虑的一些模型中，可以对不完整的列表（或一般缺失的数据）采用一种更简单的方法。事实上，如果模型是可分解的，并且缺失的部分和观察到的部分形成了不同的似然因素，我们可以采用所谓的“全信息最大似然”方法。在这种情况下，一个单位的值只是意味着可能性中没有相对参数。例如，如果B是模型中的一个不完整的列表（或在任何情况下都是一个有缺失值的列表）

$$\pi _ { A b c d s } = \sum _ {x \in \left\{ 0,1\right\}} \pi _ { x } \pi _ { a | x } \pi _ { b | x } \pi _ { c d | x } \pi _ { s }$$

然后，所有有B缺失值的单位，根据数量对可能性的贡献

$$ \sum _{x}\pi _{x}\pi _{a|x}\pi _{cd|x},$$

不需要进一步的计算工作。在局部独立模型（8.2）下，任何缺失值的模式都可以用这种方式来处理

不幸的是，并不是所有缺失的模式都可以按照这段中的描述来处理。事实上，我们需要一个所有列表同时运行的子种群，以便能够估计一个潜在的类模型。原因依赖于这样一个事实，即即使在模型（8.3）的最简单的情况下，最小的充分统计量是观察到的计数 $$n{y}$$ ，我们不能通过充分性实现数据缩减（见[12]）。因此，如果在我们的数据中，我们不能观察到$$n_{y}$$，而只是一些边际计数，我们的估计可能是有偏差的。在没有观察到高阶联合分布的情况下（即，在对数线性术语中，不能估计高阶的相互作用），这些项的影响很低，并且估计$$N{1}$$的最终偏差可以忽略不计。

# 8.4评估对潜在类别的解释

我们的模型背后的基本思想本质上是隐藏在概率记录链接问题背后的相同思想，其中二进制潜在变量旨在识别真匹配和假匹配。也就是说，在我们的模型中，我们隐式地假设有两个具有不同分布的子种群代表所期望的情况和虚假的情况，并且两个分布的混合将代表我们的数据。

当然，这种对潜在变量的解释是可以进行验证的。事实上，有限混合模型在捕获-再捕获中的常用用法是对个体间未观察到的捕获概率的异质性进行建模，这在包含可用的协变量后仍无法解释。其基本原理是通过建模观察不能直接识别的不同亚种群数据来增强拟合。通常，组件的数量的选择是一个在拟合优度和参数数量的简约性之间的平衡的问题。因此，两个潜在组件的混合不一定代表我们期望的感兴趣的子种群（范围内和范围外单元）。例如，如果我们有两组明显不同的单位，它们具有非常不同的捕获概率和相似的错误捕获率，那么一个两类模型很可能会识别这两组，而不是错误捕获和真实捕获。

当然，我们对潜在变量的解释的合理性可以通过后验来检验。事实上，除非模型被严重错误指定，否则估计的概率$$ \widehat{\pi}_{y|x}$$和估计的后验概率$$ \widehat{\pi}_{x|y}$$将有助于我们解释潜在变量，识别潜在类别的类别性质，并理解我们所做的假设是否成立。

我们对这个问题的先验知识应该指导我们评估这些可能性的合理性。例如，在许多感兴趣的情况下，我们期望几乎所有源的假捕获率都很低，以及它们之间的积极相互作用。如果明显变量都与X高度相关，并且潜在类被很好地分离出来，也就是说，如果类$$ \widehat{\pi}{y|x}$$的概率接近于0或1，那么这就构成了支持我们的论点的证据。特别是，我们期望$$ \widehat{\pi}{1|1}$$和$$ \widehat{\pi}{0|0}$$的概率接近于1。相反，如果所有源在两个潜在类中捕获概率都超过0.5，而$$ \widehat{\pi}{1|1}$$和$$ \widehat{\pi}_{0|0}$$远非一个，这将将潜在类解释为具有不同被捕获倾向的两个亚种群。

请注意，所有有限的混合模型最多都是可识别的，直到潜在类的标签的任意排列（标签切换问题）。因此，总是需要通过分析估计的参数来识别代表真实捕获的潜在类，即使模型的可拉性不是一个问题。
